{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "import scipy.stats\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "import functions\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dark background style\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# garbage collection\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 13)\n"
     ]
    }
   ],
   "source": [
    "# import CSV\n",
    "df = pd.read_csv('../data/data_v3.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "target = 'fraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1879, 13)\n",
      "(498121, 13)\n"
     ]
    }
   ],
   "source": [
    "# partitioning\n",
    "train = df[df[target].isnull() == False]\n",
    "test  = df[df[target].isnull() == True]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "y = train.sort_values('id')[target]\n",
    "test_ids = test['id']\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train shape: (1879, 4)\n",
      "- Test shape: (498121, 4)\n"
     ]
    }
   ],
   "source": [
    "### IMPORT OOF PREDS\n",
    "\n",
    "# which model to stack?\n",
    "model = 'logit'\n",
    "\n",
    "# profit threshold\n",
    "min_profit = 250\n",
    "\n",
    "# list names\n",
    "names = sorted(os.listdir('../oof_preds'))\n",
    "names = [n for n in names if int(n[n.rindex('_')+1:-4]) > min_profit]\n",
    "names = [s for s in names if model in s]\n",
    "\n",
    "# preprocessing loop\n",
    "for name in names:\n",
    "\n",
    "    # load preds\n",
    "    tmp_tr = pd.read_csv('../oof_preds/'   + str(name))\n",
    "    tmp_te = pd.read_csv('../submissions/' + str(name))\n",
    "\n",
    "    # sort OOF preds by ID\n",
    "    if 'id' in tmp_tr:\n",
    "        tmp_tr = tmp_tr.sort_values('id')\n",
    "        del tmp_tr['id']\n",
    "    \n",
    "    # rename columns\n",
    "    tmp_tr.columns = [name]    \n",
    "    tmp_te.columns = [name]    \n",
    "\n",
    "    # cbind data\n",
    "    if name == names[0]:     \n",
    "        train = tmp_tr \n",
    "        test  = tmp_te\n",
    "    else:\n",
    "        train = pd.concat([train, tmp_tr], axis = 1)\n",
    "        test  = pd.concat([test,  tmp_te], axis = 1)\n",
    "        \n",
    "# display information\n",
    "print('- Train shape:', train.shape)\n",
    "print('- Test shape:',  test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1879, 4)\n"
     ]
    }
   ],
   "source": [
    "# drop bad features\n",
    "excluded_feats = ['id']\n",
    "features = [f for f in train.columns if f not in excluded_feats]\n",
    "print(train[features].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynozDG6yivwQ"
   },
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "# settings\n",
    "cores = 10\n",
    "seed  = 999\n",
    "\n",
    "# cross-validation\n",
    "num_folds = 10\n",
    "shuffle   = True\n",
    "\n",
    "# muner of rounds\n",
    "max_rounds = 400\n",
    "stopping   = 400\n",
    "verbose    = 100\n",
    "\n",
    "# LGB parameters\n",
    "lgb_params = {\n",
    "    'boosting_type':     'gbdt',\n",
    "    'objective':         'binary',\n",
    "    'metrics':           'binary_logloss',\n",
    "    'bagging_fraction':  0.9,\n",
    "    'feature_fraction':  0.8,\n",
    "    'lambda_l1':         0.1,\n",
    "    'lambda_l2':         0.1,\n",
    "    'min_split_gain':    0.01,\n",
    "    'min_child_weight':  1,\n",
    "    'min_child_samples': 1,\n",
    "    'silent':            True,\n",
    "    'verbosity':         -1,\n",
    "    'learning_rate':     0.1,\n",
    "    'max_depth':         7,\n",
    "    'num_leaves':        70,\n",
    "    'scale_pos_weight':  1,\n",
    "    'n_estimators':      max_rounds,\n",
    "    'nthread' :          cores,\n",
    "    'random_state':      seed,\n",
    "}\n",
    "\n",
    "# data partitinoing\n",
    "folds = StratifiedKFold(n_splits = num_folds, random_state = seed, shuffle = shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders\n",
    "clfs = []\n",
    "valid_profit = np.zeros(num_folds) \n",
    "preds_test   = np.zeros(test.shape[0])\n",
    "preds_oof    = np.zeros(train.shape[0])\n",
    "importances  = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom early stopping: select the best out of 400 iterations...\n",
      "[100]\ttraining's binary_logloss: 0.0089096\ttraining's profit: 335\tvalid_1's binary_logloss: 0.0213321\tvalid_1's profit: 5\n",
      "[200]\ttraining's binary_logloss: 0.00829733\ttraining's profit: 400\tvalid_1's binary_logloss: 0.0203599\tvalid_1's profit: 30\n",
      "[300]\ttraining's binary_logloss: 0.00824127\ttraining's profit: 400\tvalid_1's binary_logloss: 0.0203045\tvalid_1's profit: 30\n",
      "[400]\ttraining's binary_logloss: 0.00824127\ttraining's profit: 400\tvalid_1's binary_logloss: 0.0203045\tvalid_1's profit: 30\n",
      "Best iteration is:\n",
      "[6]   valid_1 profit: 55; log_loss =  0.073958\n",
      "----------------------\n",
      "FOLD 1: PROFIT = 55\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 400 iterations...\n",
      "[100]\ttraining's binary_logloss: 0.00879986\ttraining's profit: 350\tvalid_1's binary_logloss: 0.0131874\tvalid_1's profit: 30\n",
      "[200]\ttraining's binary_logloss: 0.00829131\ttraining's profit: 350\tvalid_1's binary_logloss: 0.0145126\tvalid_1's profit: 30\n",
      "[300]\ttraining's binary_logloss: 0.00829131\ttraining's profit: 350\tvalid_1's binary_logloss: 0.0145126\tvalid_1's profit: 30\n",
      "[400]\ttraining's binary_logloss: 0.00829131\ttraining's profit: 350\tvalid_1's binary_logloss: 0.0145126\tvalid_1's profit: 30\n",
      "Best iteration is:\n",
      "[5]   valid_1 profit: 45; log_loss =  0.077489\n",
      "----------------------\n",
      "FOLD 2: PROFIT = 45\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 400 iterations...\n",
      "[100]\ttraining's binary_logloss: 0.0106672\ttraining's profit: 350\tvalid_1's binary_logloss: 0.0167588\tvalid_1's profit: 45\n",
      "[200]\ttraining's binary_logloss: 0.00974774\ttraining's profit: 345\tvalid_1's binary_logloss: 0.0165164\tvalid_1's profit: 45\n",
      "[300]\ttraining's binary_logloss: 0.00974774\ttraining's profit: 345\tvalid_1's binary_logloss: 0.0165164\tvalid_1's profit: 45\n",
      "[400]\ttraining's binary_logloss: 0.00974774\ttraining's profit: 345\tvalid_1's binary_logloss: 0.0165164\tvalid_1's profit: 45\n",
      "Best iteration is:\n",
      "[70]   valid_1 profit: 45; log_loss =  0.016639\n",
      "----------------------\n",
      "FOLD 3: PROFIT = 45\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 400 iterations...\n",
      "[100]\ttraining's binary_logloss: 0.00815008\ttraining's profit: 385\tvalid_1's binary_logloss: 0.0347724\tvalid_1's profit: 30\n",
      "[200]\ttraining's binary_logloss: 0.00714464\ttraining's profit: 420\tvalid_1's binary_logloss: 0.0373275\tvalid_1's profit: 30\n",
      "[300]\ttraining's binary_logloss: 0.00714221\ttraining's profit: 420\tvalid_1's binary_logloss: 0.0372963\tvalid_1's profit: 30\n",
      "[400]\ttraining's binary_logloss: 0.00714221\ttraining's profit: 420\tvalid_1's binary_logloss: 0.0372963\tvalid_1's profit: 30\n",
      "Best iteration is:\n",
      "[97]   valid_1 profit: 30; log_loss =  0.034769\n",
      "----------------------\n",
      "FOLD 4: PROFIT = 30\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 400 iterations...\n",
      "[100]\ttraining's binary_logloss: 0.00742688\ttraining's profit: 350\tvalid_1's binary_logloss: 0.0479017\tvalid_1's profit: 40\n",
      "[200]\ttraining's binary_logloss: 0.00716443\ttraining's profit: 350\tvalid_1's binary_logloss: 0.0477783\tvalid_1's profit: 40\n",
      "[300]\ttraining's binary_logloss: 0.00716443\ttraining's profit: 350\tvalid_1's binary_logloss: 0.0477783\tvalid_1's profit: 40\n",
      "[400]\ttraining's binary_logloss: 0.00716443\ttraining's profit: 350\tvalid_1's binary_logloss: 0.0477783\tvalid_1's profit: 40\n",
      "Best iteration is:\n",
      "[9]   valid_1 profit: 40; log_loss =  0.064569\n",
      "----------------------\n",
      "FOLD 5: PROFIT = 40\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 400 iterations...\n",
      "[100]\ttraining's binary_logloss: 0.00944255\ttraining's profit: 370\tvalid_1's binary_logloss: 0.0215716\tvalid_1's profit: 25\n",
      "[200]\ttraining's binary_logloss: 0.00827879\ttraining's profit: 370\tvalid_1's binary_logloss: 0.0261721\tvalid_1's profit: 25\n",
      "[300]\ttraining's binary_logloss: 0.00787946\ttraining's profit: 380\tvalid_1's binary_logloss: 0.0274891\tvalid_1's profit: 25\n",
      "[400]\ttraining's binary_logloss: 0.00787946\ttraining's profit: 380\tvalid_1's binary_logloss: 0.0274891\tvalid_1's profit: 25\n",
      "Best iteration is:\n",
      "[5]   valid_1 profit: 40; log_loss =  0.076242\n",
      "----------------------\n",
      "FOLD 6: PROFIT = 40\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 400 iterations...\n",
      "[100]\ttraining's binary_logloss: 0.00846409\ttraining's profit: 390\tvalid_1's binary_logloss: 0.00123725\tvalid_1's profit: 50\n",
      "[200]\ttraining's binary_logloss: 0.00750154\ttraining's profit: 400\tvalid_1's binary_logloss: 0.00111339\tvalid_1's profit: 50\n",
      "[300]\ttraining's binary_logloss: 0.00744826\ttraining's profit: 410\tvalid_1's binary_logloss: 0.00110897\tvalid_1's profit: 50\n",
      "[400]\ttraining's binary_logloss: 0.00744826\ttraining's profit: 410\tvalid_1's binary_logloss: 0.00110897\tvalid_1's profit: 50\n",
      "Best iteration is:\n",
      "[6]   valid_1 profit: 50; log_loss =  0.061114\n",
      "----------------------\n",
      "FOLD 7: PROFIT = 50\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 400 iterations...\n",
      "[100]\ttraining's binary_logloss: 0.00796852\ttraining's profit: 375\tvalid_1's binary_logloss: 0.015002\tvalid_1's profit: 40\n",
      "[200]\ttraining's binary_logloss: 0.00699731\ttraining's profit: 400\tvalid_1's binary_logloss: 0.0167764\tvalid_1's profit: 40\n",
      "[300]\ttraining's binary_logloss: 0.00683459\ttraining's profit: 410\tvalid_1's binary_logloss: 0.0170633\tvalid_1's profit: 40\n",
      "[400]\ttraining's binary_logloss: 0.00683459\ttraining's profit: 410\tvalid_1's binary_logloss: 0.0170633\tvalid_1's profit: 40\n",
      "Best iteration is:\n",
      "[12]   valid_1 profit: 40; log_loss =  0.04186\n",
      "----------------------\n",
      "FOLD 8: PROFIT = 40\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 400 iterations...\n",
      "[100]\ttraining's binary_logloss: 0.00742715\ttraining's profit: 360\tvalid_1's binary_logloss: 0.0321712\tvalid_1's profit: 15\n",
      "[200]\ttraining's binary_logloss: 0.00717776\ttraining's profit: 410\tvalid_1's binary_logloss: 0.0314796\tvalid_1's profit: 15\n",
      "[300]\ttraining's binary_logloss: 0.00717776\ttraining's profit: 410\tvalid_1's binary_logloss: 0.0314796\tvalid_1's profit: 15\n",
      "[400]\ttraining's binary_logloss: 0.00717776\ttraining's profit: 410\tvalid_1's binary_logloss: 0.0314796\tvalid_1's profit: 15\n",
      "Best iteration is:\n",
      "[5]   valid_1 profit: 30; log_loss =  0.085145\n",
      "----------------------\n",
      "FOLD 9: PROFIT = 30\n",
      "----------------------\n",
      "\n",
      "Custom early stopping: select the best out of 400 iterations...\n",
      "[100]\ttraining's binary_logloss: 0.00912407\ttraining's profit: 350\tvalid_1's binary_logloss: 0.0170077\tvalid_1's profit: 40\n",
      "[200]\ttraining's binary_logloss: 0.00888017\ttraining's profit: 350\tvalid_1's binary_logloss: 0.0171368\tvalid_1's profit: 40\n",
      "[300]\ttraining's binary_logloss: 0.00888017\ttraining's profit: 350\tvalid_1's binary_logloss: 0.0171368\tvalid_1's profit: 40\n",
      "[400]\ttraining's binary_logloss: 0.00888017\ttraining's profit: 350\tvalid_1's binary_logloss: 0.0171368\tvalid_1's profit: 40\n",
      "Best iteration is:\n",
      "[72]   valid_1 profit: 40; log_loss =  0.01699\n",
      "----------------------\n",
      "FOLD10: PROFIT = 40\n",
      "----------------------\n",
      "\n",
      "----------------------\n",
      "TOTAL PROFIT = 415\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "### CROSS-VALIDATION LOOP\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y)):\n",
    "    \n",
    "    # data partitioning\n",
    "    trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n",
    "           \n",
    "    # train lightGBM\n",
    "    print('Custom early stopping: select the best out of %.0f iterations...' % max_rounds)\n",
    "    clf = lgb.LGBMClassifier(**lgb_params) \n",
    "    clf = clf.fit(trn_x, trn_y, \n",
    "                  eval_set              = [(trn_x, trn_y), (val_x, val_y)], \n",
    "                  eval_metric           = prediction_reward, \n",
    "                  #eval_metric           = \"logloss\", \n",
    "                  #early_stopping_rounds = stopping,\n",
    "                  verbose               = verbose)\n",
    "    clfs.append(clf)\n",
    "    \n",
    "    # predict validation from the best iteration\n",
    "    #best_iter = clf.best_iteration_\n",
    "    best_iter = np.argmax(clf.evals_result_['valid_1']['profit']) + 1\n",
    "    val_preds = clf.predict_proba(val_x, num_iteration = best_iter)[:, 1]\n",
    "    print('Best iteration is:')\n",
    "    print('[' + str(best_iter) + ']   valid_1 profit: ' + str(prediction_reward(val_y, val_preds)[1].astype('int')) + \n",
    "          \"; log_loss = \", str(np.round(log_loss(val_y, val_preds), 6)))\n",
    "       \n",
    "    # predictions\n",
    "    preds_oof[val_idx]    = clf.predict_proba(val_x, num_iteration = best_iter)[:, 1]\n",
    "    valid_profit[n_fold]  = prediction_reward(val_y, preds_oof[val_idx])[1]\n",
    "    preds_test           += clf.predict_proba(test[features], num_iteration = best_iter)[:, 1] / folds.n_splits \n",
    "\n",
    "    ## importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df['Feature'] = features\n",
    "    fold_importance_df['Importance'] = clf.feature_importances_\n",
    "    fold_importance_df['Fold'] = n_fold + 1\n",
    "    importances = pd.concat([importances, fold_importance_df], axis = 0)\n",
    "    \n",
    "    # print performance\n",
    "    print('----------------------')\n",
    "    print('FOLD%2d: PROFIT = %.0f' % (n_fold + 1, valid_profit[n_fold]))\n",
    "    print('----------------------')\n",
    "    print('')\n",
    "        \n",
    "    # clear memory\n",
    "    del trn_x, trn_y, val_x, val_y\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "# print overall performance    \n",
    "cv_perf = np.sum(valid_profit)\n",
    "print('----------------------')\n",
    "print('TOTAL PROFIT = %.0f' % cv_perf)\n",
    "print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('profit', 415.0, True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### RECHECK PROFIT  \n",
    "prediction_reward(y, preds_oof)\n",
    "\n",
    "\n",
    "###### TRACKING RESULTS (10 folds, start = True, seed = 999)\n",
    "\n",
    "# V1: 3 logit models: 415 = 55 + 45 + 45 + 30 + 40 + 40 + 50 + 40 + 30 + 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file name\n",
    "model = 'stack_logit'\n",
    "perf  = str(round(cv_perf, 0).astype('int'))\n",
    "name  = model + '_' + perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gukkBbc9G4VH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.030495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.022627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.022627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id     fraud\n",
       "0     0  0.000534\n",
       "1     1  0.030495\n",
       "2    10  0.000480\n",
       "3   100  0.022627\n",
       "4  1000  0.022627"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export OOF preds\n",
    "oof = pd.DataFrame({'id': train.index, 'fraud': preds_oof})\n",
    "oof.to_csv('../stage2_oof_preds/' + str(name) + '.csv', index = False)\n",
    "oof.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>unlab_0</td>\n",
       "      <td>0.020242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>unlab_1</td>\n",
       "      <td>0.020242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>unlab_2</td>\n",
       "      <td>0.020242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>unlab_3</td>\n",
       "      <td>0.020242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>unlab_4</td>\n",
       "      <td>0.020242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id     fraud\n",
       "1879  unlab_0  0.020242\n",
       "1880  unlab_1  0.020242\n",
       "1881  unlab_2  0.020242\n",
       "1882  unlab_3  0.020242\n",
       "1883  unlab_4  0.020242"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check submission\n",
    "sub = pd.DataFrame({'id': test_ids, 'fraud': preds_test})\n",
    "#sub['fraud'] = np.round(sub['fraud']).astype('int')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498121, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export submission\n",
    "sub = sub[['fraud']]\n",
    "sub.to_csv('../submissions/' + str(name) + '.csv', index = False)\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of the same predictions: 0.985164\n"
     ]
    }
   ],
   "source": [
    "# check correlation with best individual submission\n",
    "prev_sub = pd.read_csv('../submissions/lgb_v8_375.csv')\n",
    "cor = np.sum(prev_sub[target] == np.round(sub.reset_index()[target])) / len(sub)\n",
    "print(\"Share of the same predictions: \" + str(np.round(cor, 6)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
