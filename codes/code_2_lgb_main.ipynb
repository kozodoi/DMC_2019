{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"code_2_lgb_main.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"LofLYLANetP5","colab_type":"code","colab":{}},"source":["# For Colab\n","#from google.colab import drive\n","#drive.mount('/gdrive')\n","#import os\n","#os.chdir(\"/gdrive/My Drive/Colab Notebooks/DMC_2019/codes\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rDg2hoRrG4UL","colab_type":"text"},"source":["# 1. SETTINGS"]},{"cell_type":"code","metadata":{"id":"2QpPWtHZG4UM","colab_type":"code","colab":{}},"source":["# import packages\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import lightgbm as lgb\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.decomposition import PCA, FastICA, FactorAnalysis\n","from sklearn.metrics import log_loss\n","from sklearn.neighbors import NearestNeighbors\n","import copy\n","import scipy.stats\n","import os\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"leWiYXK_G4UQ","colab_type":"code","colab":{}},"source":["# helper functions\n","import functions\n","from functions import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oh1I8GrTG4UT","colab_type":"code","colab":{}},"source":["# pandas options\n","pd.set_option('display.max_columns', None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXVmT0uFG4UV","colab_type":"code","colab":{}},"source":["# dark background style\n","plt.style.use('dark_background')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cgOaoV66G4UX","colab_type":"code","colab":{}},"source":["# ignore warnings\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JmYH_UjRG4Ua","colab_type":"code","colab":{}},"source":["# garbage collection\n","import gc\n","gc.enable()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NraN1BCPG4Uc","colab_type":"text"},"source":["# 2. DATA PREPARATION"]},{"cell_type":"code","metadata":{"id":"7QV5eQHHG4Ud","colab_type":"code","outputId":"193cee22-edb2-4d00-a8ec-8d70739402bd","executionInfo":{"status":"ok","timestamp":1557493047698,"user_tz":-120,"elapsed":1548,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# import CSV\n","df = pd.read_csv('../data/data_v3.csv')\n","print(df.shape)"],"execution_count":139,"outputs":[{"output_type":"stream","text":["(500000, 13)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qfsTSMBAG4Uf","colab_type":"code","colab":{}},"source":["# target variable\n","target = 'fraud'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hxJatDSBG4Uh","colab_type":"code","outputId":"37bbee7c-9e26-4708-b2a5-b7b717c9a91f","executionInfo":{"status":"ok","timestamp":1557493047702,"user_tz":-120,"elapsed":996,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# partitioning\n","train = df[df[target].isnull() == False]\n","test  = df[df[target].isnull() == True]\n","print(train.shape)\n","print(test.shape)"],"execution_count":141,"outputs":[{"output_type":"stream","text":["(1879, 13)\n","(498121, 13)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J5B6LXZq4hu_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"9ac31f2c-7590-4290-9087-7239461dea16","executionInfo":{"status":"ok","timestamp":1557494199353,"user_tz":-120,"elapsed":540,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["'''features_for_n = ['grandTotal',\n"," 'lineItemVoids',\n"," 'lineItemVoidsPerPosition',\n"," 'quantityModifications',\n"," 'scannedLineItemsPerSecond',\n"," 'scansWithoutRegistration',\n"," 'totalScanTimeInSeconds',\n"," 'valuePerSecond',\n"," 'total_items',\n"," 'weird_actions']\n","\n","train['neighbors_fraud'] = 0\n","test['neighbors_fraud'] = 0\n","\n","print('create train neighboring features')\n","nbrs = NearestNeighbors(n_neighbors=100, algorithm='ball_tree').fit(train.loc[:,features_for_n])\n","for i, obs in enumerate(train.index):\n","  distances, indices = nbrs.kneighbors(train.loc[[obs], features_for_n])\n","  train.loc[obs, 'neighbors_fraud'] = train.loc[indices[0][indices[0]!=obs], 'fraud'].mean()\n","  if i%100==0:\n","    print(i)\n","'''\n","    \n","    \n","#print('create train neighboring features')\n","#nbrs = NearestNeighbors(n_neighbors=16, algorithm='ball_tree').fit(train.loc[:,features_for_n])\n","#for i, obs in enumerate(train.index):\n","#  distances, indices = nbrs.kneighbors(train.loc[[obs], features_for_n])\n","#  train.loc[obs, 'neighbors_fraud15'] = train.loc[indices[0][indices[0]!=obs], 'fraud'].mean()\n","#  if i%100==0:\n","#    print(i)\n","    \n","#print('create test neighboring features')  \n","#nbrs = NearestNeighbors(n_neighbors=10, algorithm='ball_tree').fit(train.loc[:,features_for_n])\n","#for i, obs in enumerate(test.index):\n","#  distances, indices = nbrs.kneighbors(test.loc[[obs], features_for_n])\n","#  test.loc[obs, 'neighbors_fraud'] = train.loc[indices[0], 'fraud'].mean()\n","#  if i%1000==0:\n","#    print(i)"],"execution_count":157,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"features_for_n = ['grandTotal',\\n 'lineItemVoids',\\n 'lineItemVoidsPerPosition',\\n 'quantityModifications',\\n 'scannedLineItemsPerSecond',\\n 'scansWithoutRegistration',\\n 'totalScanTimeInSeconds',\\n 'valuePerSecond',\\n 'total_items',\\n 'weird_actions']\\n\\ntrain['neighbors_fraud'] = 0\\ntest['neighbors_fraud'] = 0\\n\\nprint('create train neighboring features')\\nnbrs = NearestNeighbors(n_neighbors=100, algorithm='ball_tree').fit(train.loc[:,features_for_n])\\nfor i, obs in enumerate(train.index):\\n  distances, indices = nbrs.kneighbors(train.loc[[obs], features_for_n])\\n  train.loc[obs, 'neighbors_fraud'] = train.loc[indices[0][indices[0]!=obs], 'fraud'].mean()\\n  if i%100==0:\\n    print(i)\\n\""]},"metadata":{"tags":[]},"execution_count":157}]},{"cell_type":"code","metadata":{"id":"vMbdrUNnG4Uk","colab_type":"code","colab":{}},"source":["# target variable\n","y = train[target]\n","del train[target], test[target]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nPX4ljoNG4Un","colab_type":"text"},"source":["# 3. MODELING"]},{"cell_type":"markdown","metadata":{"id":"B69Fdhg0G4Uo","colab_type":"text"},"source":["### PARAMETERS"]},{"cell_type":"code","metadata":{"id":"eWm2I0jDG4Uo","colab_type":"code","outputId":"128bd642-ac8e-444d-bb34-3a547cddcdf2","executionInfo":{"status":"ok","timestamp":1557493053602,"user_tz":-120,"elapsed":499,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# drop bad features\n","excluded_feats = ['id']\n","features = [f for f in train.columns if f not in excluded_feats]\n","print(train[features].shape)"],"execution_count":143,"outputs":[{"output_type":"stream","text":["(1879, 11)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HUIqo-MmG4Uq","colab_type":"code","colab":{}},"source":["# perform PCA\n","#num_comp = 5\n","#pca = PCA(n_components = num_comp)\n","#pca.fit(train[features].values)\n","#train = pd.DataFrame(pca.transform(train[features].values), columns = ['v' + str(v) for v in range(0, num_comp)])\n","#test  = pd.DataFrame(pca.transform(test[features].values),  columns = ['v' + str(v) for v in range(0, num_comp)])\n","#features = list(train.columns)\n","#print(train[features].shape)\n","#print(test[features].shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ynozDG6yivwQ","colab":{}},"source":["### PARAMETERS\n","\n","# settings\n","cores = 12\n","seed  = 23\n","\n","# cross-validation\n","num_folds = 5\n","shuffle   = True\n","\n","# muner of rounds\n","max_rounds = 600\n","stopping   = 600\n","verbose    = 200\n","\n","# LGB parameters\n","lgb_params = {\n","    'boosting_type':     'gbdt',\n","    'objective':         'binary',\n","    'metrics':           'binary_logloss',\n","    'bagging_fraction':  0.9,\n","    'feature_fraction':  0.8,\n","    'lambda_l1':         0.1,\n","    'lambda_l2':         0.1,\n","    'min_split_gain':    0.01,\n","    'min_child_weight':  2,\n","    'min_child_samples': 20,\n","    'silent':            True,\n","    'verbosity':         -1,\n","    'learning_rate':     0.1,\n","    'max_depth':         7,\n","    'num_leaves':        70,\n","    'scale_pos_weight':  1,\n","    'n_estimators':      max_rounds,\n","    'nthread' :          cores,\n","    'random_state':      seed,\n","}\n","\n","# data partitinoing\n","folds = StratifiedKFold(n_splits = num_folds, random_state = seed+100, shuffle = shuffle)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9usATBLbG4Uv","colab_type":"code","colab":{}},"source":["# placeholders\n","clfs = []\n","valid_profit = np.zeros(num_folds) \n","preds_test   = np.zeros(test.shape[0])\n","preds_oof    = np.zeros(train.shape[0])\n","importances  = pd.DataFrame()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHjOpbmYG4Ux","colab_type":"code","colab":{}},"source":["# SMOTE settings\n","from imblearn.over_sampling import SMOTE\n","sm = SMOTE(random_state = 23, n_jobs = 10, sampling_strategy = 0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OnYbk3yBG4Uz","colab_type":"text"},"source":["### CROSS-VALIDATION"]},{"cell_type":"code","metadata":{"id":"XdVpCrqxG4U0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":918},"outputId":"a2a0b2fa-9ac9-4f39-a43f-fd30f6a82a92","executionInfo":{"status":"ok","timestamp":1557493219953,"user_tz":-120,"elapsed":27595,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/-3-3kSLC4Mzw/AAAAAAAAAAI/AAAAAAAAABg/Usb9K3n3cRI/s64/photo.jpg","userId":"01253993997636551956"}}},"source":["### CROSS-VALIDATION LOOP\n","for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y)):\n","    \n","    # data partitioning\n","    trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n","    val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n","    \n","    ## remove outliers\n","    #out_idx = (np.abs(scipy.stats.zscore(trn_x)) < 10).all(axis = 1)\n","    #trn_x = trn_x[out_idx]\n","    #trn_y = trn_y[out_idx]\n","    \n","    # scale data\n","    scaler   = RobustScaler()\n","    trn_x    = pd.DataFrame(scaler.fit_transform(trn_x),      columns = features)\n","    val_x    = pd.DataFrame(scaler.transform(val_x),          columns = features)\n","    tmp_test = pd.DataFrame(scaler.transform(test[features]), columns = features)\n","\n","    # augment training data with SMOTE\n","    trn_x, trn_y = sm.fit_sample(trn_x, trn_y)\n","    trn_x = pd.DataFrame(trn_x, columns = features)\n","    trn_y = pd.Series(trn_y)\n","    \n","    # factor decomposition\n","    tmp_features = copy.deepcopy(features)\n","    #if False:\n","    #    decomp = FactorAnalysis(n_components = 11)\n","    #    decomp.fit(trn_x)\n","    #    trn_x = decomp.transform(trn_x)\n","    #    val_x = decomp.transform(val_x)\n","    #    tmp_test = decomp.transform(tmp_test)\n","    #    tmp_features = ['pc'+str(i) for i in range(decomp.n_components)]\n","    \n","    # add noise to train to reduce overfitting\n","    #trn_x += np.random.normal(0, 0.01, trn_x.shape)\n","    \n","    # mean target encoding\n","    #trn_x, val_x, tmp_test = mean_target_encoding(trn_x, val_x, test, features = ['trustLevel'], target = 'fraud', folds = 5)\n","    #features = [f for f in trn_x.columns if f not in excluded_feats]\n","        \n","    # train lightGBM\n","    print('Custom early stopping: select the best out of %.0f iterations...' % max_rounds)\n","    clf = lgb.LGBMClassifier(**lgb_params) \n","    clf = clf.fit(trn_x, trn_y, \n","                  eval_set              = [(trn_x, trn_y), (val_x, val_y)], \n","                  eval_metric           = prediction_reward, \n","                  #eval_metric           = \"logloss\", \n","                  #early_stopping_rounds = stopping,\n","                  verbose               = verbose)\n","    clfs.append(clf)\n","    \n","    # predict validation from the best iteration\n","    #best_iter = clf.best_iteration_\n","    best_iter = np.argmax(clf.evals_result_['valid_1']['profit']) + 1\n","    val_preds = clf.predict_proba(val_x, num_iteration = best_iter)[:, 1]\n","    print('Best iteration is:')\n","    print('[' + str(best_iter) + ']   valid_1 profit: ' + str(prediction_reward(val_y, val_preds)[1].astype('int')) + \n","          \"; log_loss = \", str(np.round(log_loss(val_y, val_preds), 6)))\n","       \n","    \n","############ PERFORM 1 ITERATRION OF SELF-TRAINING\n","#\n","#    # predict unlabeled data\n","#    tmp_preds_test = clf.predict_proba(tmp_test, num_iteration = best_iter)[:, 1]\n","#\n","#    # extract most confident preds\n","#    perc_ones  = 0.0001\n","#    perc_zeros = 0.0001\n","#    pmax = np.quantile(tmp_preds_test, 1 - perc_ones)\n","#    pmin = np.quantile(tmp_preds_test, perc_zeros)\n","#    tmp_preds_test[tmp_preds_test >= pmax] = 1\n","#    tmp_preds_test[tmp_preds_test <= pmin] = 0\n","#    confident_ones  = np.where(tmp_preds_test == 1)\n","#    confident_zeros = np.where(tmp_preds_test == 0)\n","#    confident_ones  = confident_ones[0][0:np.round(len(tmp_test)  * perc_ones).astype('int')]\n","#    confident_zeros = confident_zeros[0][0:np.round(len(tmp_test) * perc_zeros).astype('int')]\n","#    confident_idx   = np.concatenate((confident_ones, confident_zeros))\n","#\n","#    # append new data to train\n","#    test_X = tmp_test.iloc[confident_idx]\n","#    test_y = pd.Series(tmp_preds_test[confident_idx])\n","#    trn_x  = trn_x.append(test_X)\n","#    trn_y  = trn_y.append(test_y)\n","#    print('--------------------------------')\n","#    print('Added %.0f cases to training data...' % len(test_y))\n","#    print('--------------------------------')\n","#\n","#    # retrain lightGBM\n","#    print('Custom early stopping: select the best out of %.0f iterations...' % max_rounds)\n","#    clf = lgb.LGBMClassifier(**lgb_params) \n","#    clf = clf.fit(trn_x, trn_y, \n","#                  eval_set              = [(trn_x, trn_y), (val_x, val_y)], \n","#                  eval_metric           = prediction_reward, \n","#                  verbose               = verbose)\n","#\n","#    # find the best iteration\n","#    best_iter = np.argmax(clf.evals_result_['valid_1']['profit']) + 1\n","#    print('Best iteration is:')\n","#    print('[' + str(best_iter) + ']   valid_1 profit: ' + \n","#          str(prediction_reward(val_y, clf.predict_proba(val_x, num_iteration = best_iter)[:, 1])[1].astype('int')) + \n","#          \"; log_loss = \", str(np.round(log_loss(val_y, clf.predict_proba(val_x, num_iteration = best_iter)[:, 1]), 6)))\n","#    \n","############ PERFORM 1 ITERATRION OF SELF-TRAINING\n","\n","\n","    # save predictions\n","    preds_oof[val_idx]    = clf.predict_proba(val_x, num_iteration = best_iter)[:, 1]\n","    valid_profit[n_fold]  = prediction_reward(val_y, preds_oof[val_idx])[1]\n","    #preds_test           += clf.predict_proba(tmp_test, num_iteration = best_iter)[:, 1] / folds.n_splits \n","\n","    ## importance\n","    fold_importance_df = pd.DataFrame()\n","    fold_importance_df['Feature'] = tmp_features\n","    fold_importance_df['Importance'] = clf.feature_importances_\n","    fold_importance_df['Fold'] = n_fold + 1\n","    importances = pd.concat([importances, fold_importance_df], axis = 0)\n","    \n","    # print performance\n","    print('--------------------------------')\n","    print('FOLD%2d: PROFIT = %.0f' % (n_fold + 1, valid_profit[n_fold]))\n","    print('--------------------------------')\n","    print('')\n","        \n","    # clear memory\n","    del trn_x, trn_y, val_x, val_y\n","    gc.collect()\n","    \n","    # uncomment for mean target encoding\n","    #features = [f for f in train.columns if f not in excluded_feats]\n","    \n","    \n","# print overall performance    \n","cv_perf = np.sum(valid_profit)\n","print('--------------------------------')\n","print('TOTAL PROFIT = %.0f' % cv_perf)\n","print('--------------------------------')"],"execution_count":156,"outputs":[{"output_type":"stream","text":["Custom early stopping: select the best out of 600 iterations...\n","[200]\ttraining's binary_logloss: 0.00555302\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0233971\tvalid_1's profit: 70\n","[400]\ttraining's binary_logloss: 0.00449244\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0226965\tvalid_1's profit: 70\n","[600]\ttraining's binary_logloss: 0.00434247\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0227367\tvalid_1's profit: 70\n","Best iteration is:\n","[55]   valid_1 profit: 70; log_loss =  0.033528\n","--------------------------------\n","FOLD 1: PROFIT = 70\n","--------------------------------\n","\n","Custom early stopping: select the best out of 600 iterations...\n","[200]\ttraining's binary_logloss: 0.00518847\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0236502\tvalid_1's profit: 40\n","[400]\ttraining's binary_logloss: 0.00445218\ttraining's profit: 710\tvalid_1's binary_logloss: 0.023578\tvalid_1's profit: 40\n","[600]\ttraining's binary_logloss: 0.00437689\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0236502\tvalid_1's profit: 40\n","Best iteration is:\n","[46]   valid_1 profit: 75; log_loss =  0.031308\n","--------------------------------\n","FOLD 2: PROFIT = 75\n","--------------------------------\n","\n","Custom early stopping: select the best out of 600 iterations...\n","[200]\ttraining's binary_logloss: 0.00557647\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0153807\tvalid_1's profit: 70\n","[400]\ttraining's binary_logloss: 0.00450454\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0149307\tvalid_1's profit: 95\n","[600]\ttraining's binary_logloss: 0.00435153\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0150815\tvalid_1's profit: 95\n","Best iteration is:\n","[358]   valid_1 profit: 95; log_loss =  0.014857\n","--------------------------------\n","FOLD 3: PROFIT = 95\n","--------------------------------\n","\n","Custom early stopping: select the best out of 600 iterations...\n","[200]\ttraining's binary_logloss: 0.00539962\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0301056\tvalid_1's profit: 55\n","[400]\ttraining's binary_logloss: 0.00440562\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0315406\tvalid_1's profit: 55\n","[600]\ttraining's binary_logloss: 0.00430318\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0318089\tvalid_1's profit: 55\n","Best iteration is:\n","[148]   valid_1 profit: 55; log_loss =  0.030398\n","--------------------------------\n","FOLD 4: PROFIT = 55\n","--------------------------------\n","\n","Custom early stopping: select the best out of 600 iterations...\n","[200]\ttraining's binary_logloss: 0.00511066\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0288212\tvalid_1's profit: 45\n","[400]\ttraining's binary_logloss: 0.00434681\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0287326\tvalid_1's profit: 45\n","[600]\ttraining's binary_logloss: 0.00430108\ttraining's profit: 710\tvalid_1's binary_logloss: 0.0288195\tvalid_1's profit: 45\n","Best iteration is:\n","[31]   valid_1 profit: 45; log_loss =  0.047798\n","--------------------------------\n","FOLD 5: PROFIT = 45\n","--------------------------------\n","\n","--------------------------------\n","TOTAL PROFIT = 340\n","--------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qRJGFSmyG4U3","colab_type":"code","colab":{}},"source":["##### RECHECK PROFIT  \n","prediction_reward(y, preds_oof)\n","\n","\n","###### TRACKING RESULTS (5 folds, strat = True, seed = 23)\n","\n","# V1: lgb, 5 folds, default features:   80\n","# V2: add feature:  no. total items:   250\n","# V3: use logloss for ES, not profit:  260\n","# V4: add feature: no. weird actions:  275\n","# V5: custom earlystop for profit:     320\n","# V6: add SMOTE for minority class:    335\n","# V7: add robust data scaling:         350 = 95 + 55 + 75 + 35 + 90\n","# V8: increase learning rate to 0.1:   375 = 95 + 65 + 75 + 50 + 90"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qYJPn6jmG4U6","colab_type":"code","colab":{}},"source":["##### VARIABLE IMPORTANCE\n","\n","# load importance    \n","top_feats = 100\n","cols = importances[['Feature', 'Importance']].groupby('Feature').mean().sort_values(by = 'Importance', ascending = False)[0:top_feats].index\n","importance = importances.loc[importances.Feature.isin(cols)]\n","    \n","# plot variable importance\n","plt.figure(figsize = (10, 6))\n","sns.barplot(x = 'Importance', y = 'Feature', data = importance.sort_values(by = 'Importance', ascending = False))\n","plt.tight_layout()\n","\n","# save plot as pdf\n","plt.savefig('../var_importance.pdf')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cbRYVd-iG4U_","colab_type":"text"},"source":["### CUTOFF OPTIMIZATION"]},{"cell_type":"code","metadata":{"id":"RL3esc0gG4VB","colab_type":"code","colab":{}},"source":["##### OPTIMIZE CUTOFF\n","\n","# set step\n","step = 100\n","\n","# search\n","cutoffs = []\n","profits = []\n","for i in range(0, step):\n","    cutoffs.append(i / step)\n","    profits.append(recompute_reward(y, preds_oof, cutoff = cutoffs[i]))\n","        \n","# results\n","plt.figure(figsize = (10,4))\n","sns.lineplot(x = cutoffs[10:step], y = profits[10:step], color = 'red')\n","plt.tight_layout()\n","plt.axvline(x = cutoffs[np.argmax(profits)], color = 'white', linestyle = '--')\n","print('- optimal cutoff = %.4f' % cutoffs[np.argmax(profits)])\n","print('- optimal profit = %.4f' % profits[np.argmax(profits)])\n","plt.savefig('../cutoff_selection.pdf')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2dsi_jeGG4VE","colab_type":"text"},"source":["# 4. SUBMISSION"]},{"cell_type":"code","metadata":{"id":"_Tt_FxCwG4VF","colab_type":"code","colab":{}},"source":["# file name\n","model = 'lgb_v8'\n","perf  = str(round(cv_perf, 0).astype('int'))\n","name  = model + '_' + perf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gukkBbc9G4VH","colab_type":"code","colab":{}},"source":["# export OOF preds\n","oof = pd.DataFrame({'id': train['id'], 'fraud': preds_oof})\n","oof.to_csv('../oof_preds/' + str(name) + '.csv', index = False)\n","oof.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1cJ8GWH7G4VJ","colab_type":"code","colab":{}},"source":["# check submission\n","sub = pd.DataFrame({'id': test['id'], 'fraud': preds_test})\n","sub['fraud'] = np.round(sub['fraud']).astype('int')\n","sub.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HDcmUKk4G4VM","colab_type":"code","colab":{}},"source":["# export submission\n","sub = sub[['fraud']]\n","sub.to_csv('../submissions/' + str(name) + '.csv', index = False)\n","sub.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KSlPhL4dG4VO","colab_type":"code","colab":{}},"source":["# check correlation with previous submission\n","prev_sub = pd.read_csv('../submissions/lgb_v8_375.csv')\n","cor = np.sum(prev_sub[target] == sub.reset_index()[target]) / len(sub)\n","print(\"Share of the same predictions: \" + str(np.round(cor, 6)))"],"execution_count":0,"outputs":[]}]}